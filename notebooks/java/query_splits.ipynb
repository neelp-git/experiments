{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Splitting-Large-Data-Sets-for-Parallel-Processing-of-Queries\" data-toc-modified-id=\"Splitting-Large-Data-Sets-for-Parallel-Processing-of-Queries-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Splitting Large Data Sets for Parallel Processing of Queries</a></span><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Prerequisites\" data-toc-modified-id=\"Prerequisites-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Prerequisites</a></span></li><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Setup</a></span><ul class=\"toc-item\"><li><span><a href=\"#Ensure-database-is-running\" data-toc-modified-id=\"Ensure-database-is-running-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Ensure database is running</a></span></li><li><span><a href=\"#Download-and-install-additional-components.\" data-toc-modified-id=\"Download-and-install-additional-components.-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Download and install additional components.</a></span></li><li><span><a href=\"#Initialize-Client\" data-toc-modified-id=\"Initialize-Client-1.3.3\"><span class=\"toc-item-num\">1.3.3&nbsp;&nbsp;</span>Initialize Client</a></span><ul class=\"toc-item\"><li><span><a href=\"#Initialize-event-loops-for-async-processing-mode\" data-toc-modified-id=\"Initialize-event-loops-for-async-processing-mode-1.3.3.1\"><span class=\"toc-item-num\">1.3.3.1&nbsp;&nbsp;</span>Initialize event loops for async processing mode</a></span></li><li><span><a href=\"#Initialize-client-with-event-loops\" data-toc-modified-id=\"Initialize-client-with-event-loops-1.3.3.2\"><span class=\"toc-item-num\">1.3.3.2&nbsp;&nbsp;</span>Initialize client with event loops</a></span></li></ul></li><li><span><a href=\"#Includes-and-Constants\" data-toc-modified-id=\"Includes-and-Constants-1.3.4\"><span class=\"toc-item-num\">1.3.4&nbsp;&nbsp;</span>Includes and Constants</a></span></li><li><span><a href=\"#Populate-Test-Data.\" data-toc-modified-id=\"Populate-Test-Data.-1.3.5\"><span class=\"toc-item-num\">1.3.5&nbsp;&nbsp;</span>Populate Test Data.</a></span></li></ul></li></ul></li><li><span><a href=\"#Overview\" data-toc-modified-id=\"Overview-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Overview</a></span></li><li><span><a href=\"#Dividing-Partitions-into-Requested-Splits\" data-toc-modified-id=\"Dividing-Partitions-into-Requested-Splits-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Dividing Partitions into Requested Splits</a></span></li><li><span><a href=\"#Parallel-Query-Framework\" data-toc-modified-id=\"Parallel-Query-Framework-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Parallel Query Framework</a></span><ul class=\"toc-item\"><li><span><a href=\"#Global-parameters\" data-toc-modified-id=\"Global-parameters-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Global parameters</a></span></li></ul></li><li><span><a href=\"#Running-Parallel-Queries-with-Interesting-Parameter-Variations\" data-toc-modified-id=\"Running-Parallel-Queries-with-Interesting-Parameter-Variations-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Running Parallel Queries with Interesting Parameter Variations</a></span><ul class=\"toc-item\"><li><span><a href=\"#Varying-number-of-splits-and-split-types\" data-toc-modified-id=\"Varying-number-of-splits-and-split-types-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Varying number of splits and split types</a></span></li><li><span><a href=\"#Varying-number-of-workers-in-sync-mode\" data-toc-modified-id=\"Varying-number-of-workers-in-sync-mode-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Varying number of workers in sync mode</a></span></li><li><span><a href=\"#Varying-number-of-workers-in-sync-and-async-mode\" data-toc-modified-id=\"Varying-number-of-workers-in-sync-and-async-mode-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Varying number of workers in sync and async mode</a></span></li><li><span><a href=\"#Varying-query-type-and-filter\" data-toc-modified-id=\"Varying-query-type-and-filter-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Varying query type and filter</a></span></li><li><span><a href=\"#Varying-max-records-chunk-size\" data-toc-modified-id=\"Varying-max-records-chunk-size-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span>Varying max-records chunk size</a></span></li><li><span><a href=\"#Select-and-run-with-your-own-parameters\" data-toc-modified-id=\"Select-and-run-with-your-own-parameters-5.6\"><span class=\"toc-item-num\">5.6&nbsp;&nbsp;</span>Select and run with your own parameters</a></span></li></ul></li><li><span><a href=\"#Takeaways-and-Conclusion\" data-toc-modified-id=\"Takeaways-and-Conclusion-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Takeaways and Conclusion</a></span></li><li><span><a href=\"#Further-Exploration-and-Resources\" data-toc-modified-id=\"Further-Exploration-and-Resources-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Further Exploration and Resources</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Large Data Sets for Parallel Processing of Queries\n",
    "This tutorial describes a scheme for dividing a large data set into equal splits for parallel processing of queries.\n",
    "\n",
    "This notebook requires the Aerospike Database running locally with Java kernel and Aerospike Java Client. To create a Docker container that satisfies the requirements and holds a copy of Aerospike notebooks, visit the [Aerospike Notebooks Repo](https://github.com/aerospike-examples/interactive-notebooks)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this notebook, we will implement a scheme to divide a set or the entire namespace in Aerospike into equal splits that can be queried in parallel. We will create a test framework that allows the splits to be processed over a range of parameters such as the number of workers, query and filter options, and processing mode. We will then run various combinations of splits, workers, and processing mode on the test data, and ensure the results remain the same for specific query and filter choices.\n",
    "\n",
    "Please refer to the adjunct blog post [Processing Large Data Sets with Fine Grained Streams](../blog/fine-grained-streams) for details.\n",
    "\n",
    "The specific topics covered in this notebook include:\n",
    "- A scheme for dividing data equally over an arbitrary number of splits.\n",
    "- The test framework to process the splits in parallel using a range of parameters such as the number of workers, query and filter options, and sync and async modes.\n",
    "- Putting it to test with different values for splits, workers, query, filter, and processing mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "This tutorial assumes familiarity with the following topics:\n",
    "- [Hello World](hello_world.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensure database is running\n",
    "This notebook requires that Aerospike database is running. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io.github.spencerpark.ijava.IJava;\n",
    "import io.github.spencerpark.jupyter.kernel.magic.common.Shell;\n",
    "IJava.getKernelInstance().getMagics().registerMagics(Shell.class);\n",
    "%sh asd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and install additional components.\n",
    "Install the Java client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%loadFromPOM\n",
    "<dependencies>\n",
    "  <dependency>\n",
    "    <groupId>com.aerospike</groupId>\n",
    "    <artifactId>aerospike-client</artifactId>\n",
    "    <version>6.1.0</version>\n",
    "  </dependency>\n",
    "</dependencies>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Client\n",
    "Initialize the client that can be used for both sync and async processing modes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize event loops for async processing mode\n",
    "We will use async processiong using NIO event loops, but the other event loop types may also be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Throttles initialized for 2 loops with 50 concurrent operations per loop.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "java.io.PrintStream@1afb8b3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import java.util.concurrent.atomic.AtomicInteger;\n",
    "import com.aerospike.client.async.EventPolicy;\n",
    "import com.aerospike.client.async.EventLoops;\n",
    "import com.aerospike.client.async.EventLoop;\n",
    "import com.aerospike.client.async.Throttles;\n",
    "import com.aerospike.client.async.Monitor;\n",
    "import com.aerospike.client.async.NioEventLoops;\n",
    "import com.aerospike.client.listener.RecordSequenceListener;\n",
    "\n",
    "// initialize event loops \n",
    "final int NumLoops = 2;\n",
    "final int CommandsPerEventLoop = 50;\n",
    "final int DelayQueueSize = 50;\n",
    "\n",
    "EventPolicy eventPolicy = new EventPolicy();\n",
    "eventPolicy.maxCommandsInProcess = CommandsPerEventLoop;\n",
    "eventPolicy.maxCommandsInQueue = DelayQueueSize;\n",
    "EventLoops eventLoops = new NioEventLoops(eventPolicy, NumLoops);\n",
    "\n",
    "// initialize event loop throttles\n",
    "Throttles throttles = new Throttles(NumLoops, CommandsPerEventLoop);\n",
    "\n",
    "System.out.format(\"Throttles initialized for %s loops with %s concurrent operations per loop.\\n\", \n",
    "                    NumLoops, CommandsPerEventLoop);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize client with event loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized the client and connected to the cluster.\n"
     ]
    }
   ],
   "source": [
    "import com.aerospike.client.AerospikeClient;\n",
    "import com.aerospike.client.Host;\n",
    "import com.aerospike.client.policy.ClientPolicy;\n",
    "\n",
    "// initialize the client \n",
    "final int MaxConnPerNode = 10000; // adjust accordingly for max workers\n",
    "ClientPolicy clientPolicy = new ClientPolicy();\n",
    "clientPolicy.maxConnsPerNode = MaxConnPerNode;\n",
    "clientPolicy.eventLoops = eventLoops;\n",
    "int concurrentMax = CommandsPerEventLoop * NumLoops;\n",
    "if (clientPolicy.maxConnsPerNode < concurrentMax) {\n",
    "    clientPolicy.maxConnsPerNode = concurrentMax; \n",
    "}\n",
    "Host[] hosts = Host.parseHosts(\"localhost\", 3000); \n",
    "\n",
    "AerospikeClient client = new AerospikeClient(clientPolicy, hosts);\n",
    "\n",
    "System.out.println(\"Initialized the client and connected to the cluster.\");;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Includes and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.util.concurrent.atomic.AtomicInteger;\n",
    "import java.util.concurrent.atomic.AtomicLong;\n",
    "import com.aerospike.client.AerospikeException;\n",
    "import com.aerospike.client.Bin;\n",
    "import com.aerospike.client.Key;\n",
    "import com.aerospike.client.policy.WritePolicy;\n",
    "import com.aerospike.client.query.Filter;\n",
    "import com.aerospike.client.query.PartitionFilter;\n",
    "import com.aerospike.client.query.RecordSet;\n",
    "import com.aerospike.client.query.Statement;\n",
    "import com.aerospike.client.Record;\n",
    "import com.aerospike.client.exp.Exp;\n",
    "import com.aerospike.client.policy.Policy;\n",
    "import com.aerospike.client.policy.QueryPolicy;\n",
    "import com.aerospike.client.query.IndexType;\n",
    "import com.aerospike.client.task.IndexTask;\n",
    "import com.aerospike.client.ResultCode;\n",
    "\n",
    "final String Namespace = \"test\";\n",
    "final String Set = \"query-splits\";\n",
    "final String KeyPrefix = \"id-\";\n",
    "final Integer NumRecords = 100000;         // CHANGE TO THE REQUIRED NUMBER OF TEST DATA RECORDS\n",
    "\n",
    "final int MIN_NUM_SPLITS = 1;              // at-least the requested number of splits\n",
    "final int EXACT_NUM_SPLITS = 0;            // exactly the requested number of splits\n",
    "final int MAX_NUM_SPLITS = -1;             // at-most the requested number of splits\n",
    "final int PROCESSING_MODE_SYNC = 0;        // sync processing mode\n",
    "final int PROCESSING_MODE_ASYNC = 1;       // async processing mode\n",
    "final int PRIMARY_INDEX_QUERY = 0;         // primary index query (scan)\n",
    "final int SECONDARY_INDEX_QUERY = 1;       // secondary index query - uses secondaryIndexQueryPredicate\n",
    "final int QUERY_FILTER_NONE = 0;           // no additional filter in query\n",
    "final int QUERY_FILTER_INCLUDE = 1;        // include the specified filter - uses includeQueryFilterExp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate Test Data.\n",
    "The test data consists of NumRecords records, each with a user key \"id-\\<i\\>\", an integer bin \"bin1\" with value i, and another integer bin with value 10*i, where 1 \\<= i \\<= NumRecords. An integer secondary index is created on \"bin1\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data populated.\n"
     ]
    }
   ],
   "source": [
    "// convenience function to initialize test data\n",
    "void initializeTestData() {\n",
    "    WritePolicy wpolicy = new WritePolicy();\n",
    "    wpolicy.sendKey = true;\n",
    "    for (int i = 1; i <= NumRecords; i++) {\n",
    "        Key key = new Key(Namespace, Set, KeyPrefix+i);\n",
    "        Bin bin1 = new Bin(new String(\"bin1\"), i);\n",
    "        Bin bin2 = new Bin(new String(\"bin2\"), 10*i);\n",
    "        client.put(wpolicy, key, bin1, bin2);\n",
    "    }\n",
    "}\n",
    "initializeTestData();\n",
    "System.out.println(\"Test data populated.\");;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created index idx_bin1_number_idx on ns=test set=query-splits bin=bin1."
     ]
    }
   ],
   "source": [
    "Policy policy = new Policy();\n",
    "policy.socketTimeout = 0; // Do not timeout on index create.\n",
    "\n",
    "final String IndexName = \"idx_bin1_number_idx\";\n",
    "\n",
    "try {\n",
    "    IndexTask task = client.createIndex(policy, Namespace, Set, IndexName, \n",
    "                                        \"bin1\", IndexType.NUMERIC);\n",
    "    task.waitTillComplete();\n",
    "}\n",
    "catch (AerospikeException ae) {\n",
    "    if (ae.getResultCode() != ResultCode.INDEX_ALREADY_EXISTS) {\n",
    "        throw ae;\n",
    "    }\n",
    "}\n",
    "\n",
    "System.out.format(\"Created index %s on ns=%s set=%s bin=%s.\", \n",
    "                                    IndexName, Namespace, Set, \"bin1\");;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "The main sections consist of:\n",
    "- Dividing partitions into N splits\n",
    "- Parallel query framework\n",
    "- Experimenting with parameter variations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividing Partitions into Requested Splits\n",
    "The main function assignSplits() returns an array of assignments across the requested number of splits. Each assignment has:\n",
    "\n",
    "Partial or full partition assignment\n",
    "A full partition assignment has the range of partitions , specified as the start partition id and count\n",
    "A partial partition assignment has the partition id, modulo (division) factor, first sub-partition id, second sub-partition id (can be null)\n",
    "The assignment parameters directly correspond to PartitionFilter specification in the queryPartitions API. For example, in Java, the query over full parttiions can be translated as follows:\n",
    "\n",
    "PartitionFilter pFilter = PartitionFilter.range(startPartitionId, partitionCount) Statement stmt = new Statement(); stmt.setNamespace(namespace); stmt.setSetName(setName); stmt.setBinNames(bin1, ...); stmt.setMaxRecords(maxRecords); RecordSet rs = client.queryPartitions(qPolicy, qStatement, pFilter);\n",
    "\n",
    "A query over sub-partition assignments is translated as follows:\n",
    "\n",
    "PartitionFilter pFilter = PartitionFilter.id(partitionId) QueryPolicy qPolicy = new QueryPolicy(client.queryPolicyDefault); qPolicy.filterExp = Exp.build( Exp.or( Exp.eq(Exp.moduloDigest(moduloFactor), Exp.val(subPartitionId1)), Exp.eq(Exp.moduloDigest(moduloFactor), Exp.val(subPartitionId2))));\n",
    "\n",
    "RecordSet rs = client.queryPartitions(qPolicy, qStatement, pFilter);\n",
    "\n",
    "Each chunk of maxRecords retrieved is processed and the query is re-issued until pFilter.isDone() returns true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitAssignment {\n",
    "    boolean isFullPartitionAssignment; // false for sub-partition assignments\n",
    "    Integer fullPartitionStartId;\n",
    "    Integer fullPartitionCount;\n",
    "    Integer partialPartitionId;        // partition id of the sub-partition(s)\n",
    "    Integer subPartitonModuloFactor;\n",
    "    Integer firstSubpartition;         // always valid for a sub-partition assignment\n",
    "    Integer secondSubpartition;        // can be null if only one sub-partition assigned\n",
    "    \n",
    "    SplitAssignment (int startId, int count) {\n",
    "        this.isFullPartitionAssignment = true;\n",
    "        this.fullPartitionStartId = startId;\n",
    "        this.fullPartitionCount = count;\n",
    "    }\n",
    "    \n",
    "    SplitAssignment(int partialPartitionId, int moduloFactor, \n",
    "                    int firstSubpartion, Integer secondSubpartition) {\n",
    "        this.isFullPartitionAssignment = false;\n",
    "        this.partialPartitionId = partialPartitionId;\n",
    "        this.subPartitonModuloFactor = moduloFactor;\n",
    "        this.firstSubpartition = firstSubpartion;\n",
    "        this.secondSubpartition = secondSubpartition;                                   \n",
    "    }\n",
    "}  \n",
    "\n",
    "final int FactorsOf4096[] = {1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096};\n",
    "\n",
    "// split assignment types:\n",
    "//       MAX_NUM_SPLITS At most requested number of splits (can be fewer), but same sized.\n",
    "//       MIN_NUM_SPLITS At least requested number of splits (can be more), but same sized\n",
    "//       EXACT_NUM_SPLITS Exactly requested number of splits, but can be different sized.\n",
    "\n",
    "SplitAssignment[] assignSplits(int reqSplits, int splitType) {\n",
    "    int numSplits = 0;\n",
    "    SplitAssignment[] assignments = null;\n",
    "    \n",
    "    if (splitType == MAX_NUM_SPLITS) { // at most reqSplits\n",
    "       if (reqSplits < 2*4096) {\n",
    "            // Case 1: N < 2*4096: Full partition assignments\n",
    "            // Closest approximation of splits, numSplits: factor of 4096 that is <= reqSplits\n",
    "            for (int i = FactorsOf4096.length - 1; i >= 0; i--) {\n",
    "                if (FactorsOf4096[i] <= reqSplits) {\n",
    "                    numSplits = FactorsOf4096[i];\n",
    "                    break;\n",
    "                }\n",
    "            }\n",
    "            // Number of partitions in each split, count: 4096/numSplits\n",
    "            int count = 4096 / numSplits;\n",
    "            // Partitions in split i: i*count to (i+1)*n (upper bound exclusive)\n",
    "            assignments = new SplitAssignment[numSplits];\n",
    "            for (int i = 0; i < numSplits; i++) {\n",
    "                assignments[i] = new SplitAssignment(i*count, count);\n",
    "            }\n",
    "        } else {        \n",
    "            // Case 2: N >= 2*4096: Sub-partition assignment\n",
    "            //Closest approximation of splits, numSplits: multiple of 4096 that is <= reqSplits\n",
    "            numSplits = 4096 * (int)Math.floor((double)reqSplits/4096);\n",
    "            //Number of sub-partitions per partition, s: numSplits/4096\n",
    "            int moduloFactor = numSplits/4096;\n",
    "            //Sub-partition in split i: (floor(i/s), i%s, s)\n",
    "            assignments = new SplitAssignment[numSplits];\n",
    "            for (int i = 0; i < numSplits; i++) {\n",
    "                assignments[i] = new SplitAssignment((int)Math.floor((double)i/moduloFactor), moduloFactor,\n",
    "                                                       i % moduloFactor, null);\n",
    "            }\n",
    "        }\n",
    "        \n",
    "    } else if (splitType == MIN_NUM_SPLITS) { // at least reqSplits\n",
    "       if (reqSplits <= 4096) {\n",
    "            // Case 1: N <= 4096: Full partition assignments\n",
    "            // Closest approximation of splits, numSplits: factor of 4096 that is >= reqSplits\n",
    "            for (int f: FactorsOf4096) {\n",
    "                if (f >= reqSplits) {\n",
    "                    numSplits = f;\n",
    "                    break;\n",
    "                }\n",
    "            }\n",
    "            // Number of partitions in each split, count: 4096/numSplits\n",
    "            int count = 4096 / numSplits;\n",
    "            // Partitions in split i: i*count to (i+1)*n (upper bound exclusive)\n",
    "            assignments = new SplitAssignment[numSplits];\n",
    "            for (int i = 0; i < numSplits; i++) {\n",
    "                assignments[i] = new SplitAssignment(i*count, count);\n",
    "            }\n",
    "        } else {        \n",
    "            // Case 2: N > 4096: Sub-partition assignment\n",
    "            //Closest approximation of splits, numSplits: multiple of 4096 that is >= reqSplits\n",
    "            numSplits = 4096 * (int)Math.ceil((double)reqSplits/4096);\n",
    "            //Number of sub-partitions per partition, s: numSplits/4096\n",
    "            int moduloFactor = numSplits/4096;\n",
    "            //Sub-partition in split i: (floor(i/s), i%s, s)\n",
    "            assignments = new SplitAssignment[numSplits];\n",
    "            for (int i = 0; i < numSplits; i++) {\n",
    "                assignments[i] = new SplitAssignment((int)Math.floor((double)i/moduloFactor), moduloFactor,\n",
    "                                                       i % moduloFactor, null);\n",
    "            }\n",
    "        }\n",
    "\n",
    "    } else { // exactly reqSplits\n",
    "        if (reqSplits <= 4096) {\n",
    "            // Case 1: N <= 4096\n",
    "            // Each split is assigned full partitions only (maxModulo=1), \n",
    "            //.   with some may get an additional partition.\n",
    "            // Evenly assign partitions over N splits.\n",
    "            // Number of full partitions per split, n: floor(4096/N)\n",
    "            int minPartitionsPerSplit = (int)Math.floor((double)4096/reqSplits);\n",
    "            // Remaining partitions r are allocated in full to splits 0 to r-1\n",
    "            int remainingPartitions = 4096 - minPartitionsPerSplit*reqSplits;\n",
    "            // Assign minPartitionsPerSplit+1 to the first remainingPartitions splits, and\n",
    "            //   minPartitionsPerSplit to the rest.\n",
    "            int nextStartPartition = 0;\n",
    "            assignments = new SplitAssignment[reqSplits];\n",
    "            for (int i=0; i < reqSplits; i++){\n",
    "                if (i < remainingPartitions) {\n",
    "                    assignments[i] = new SplitAssignment(nextStartPartition, minPartitionsPerSplit+1);\n",
    "                    nextStartPartition += minPartitionsPerSplit+1;\n",
    "                } else {\n",
    "                    assignments[i] = new SplitAssignment(nextStartPartition, minPartitionsPerSplit);\n",
    "                    nextStartPartition += minPartitionsPerSplit;\n",
    "                }\n",
    "            }\n",
    "        } else {\n",
    "            // Case 2: N > 4096\n",
    "            // Each split is assigned one or two subpartitions in the same partition.\n",
    "            // Divide each partition into m (modulo-factor) subparittions: ceiling(N/4096) â€“ \n",
    "            //    the ceiling function ensures assignment across all N splits.\n",
    "            int moduloFactor = (int)Math.ceil((double)reqSplits/4096);\n",
    "            // 4096*moduloFactor sub-partitions are available to be assigned across reqSplits\n",
    "            // reqSplits sub-partitions are assigned one per split\n",
    "            // Remaining sub-partitions r = (4096*moduloFactor - reqSplits) are allocated to splits 0 to r-1.\n",
    "            int remainingSubPartitions = 4096*moduloFactor - reqSplits;\n",
    "            // Assign 2 sub-partitions to the first remainingSubPartitions splits while ensuring both\n",
    "            //.  sub-partitions are from the same partition, and 1 sub-partition to the rest.\n",
    "            int twoSubsSplitIndex = 0; // varies from 0 to remainingSubPartitions-1\n",
    "            int oneSubSplitIndex = remainingSubPartitions; // varies from remainingSubPartitions to reqSplits\n",
    "            assignments = new SplitAssignment[reqSplits];\n",
    "            for (int i=0; i < 4096; i++) {\n",
    "                int subPartition = 0;\n",
    "                while (subPartition < moduloFactor) {\n",
    "                    if (twoSubsSplitIndex < remainingSubPartitions &&\n",
    "                            subPartition+1 < moduloFactor) { // both subpartitions must be in the same partition\n",
    "                        assignments[twoSubsSplitIndex] = new SplitAssignment(i, moduloFactor,\n",
    "                                                           subPartition, subPartition+1);\n",
    "                        twoSubsSplitIndex++;\n",
    "                        subPartition += 2; \n",
    "                    } else {\n",
    "                        // single partition assignment\n",
    "                        assignments[oneSubSplitIndex] = new SplitAssignment(i, moduloFactor,\n",
    "                                                           subPartition, null);\n",
    "                        oneSubSplitIndex++;\n",
    "                        subPartition++; \n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return assignments;\n",
    "}\n",
    "\n",
    "void assignmentSummary(SplitAssignment[] sa) {\n",
    "    System.out.format(\"%d splits: \\n\", sa.length);\n",
    "    if (sa[0].isFullPartitionAssignment) {\n",
    "        int i = 0;\n",
    "        System.out.format(\"\\tSplit: %s, start: %s, count: %s\\n\", \n",
    "                    i, sa[i].fullPartitionStartId, sa[i].fullPartitionCount);\n",
    "        int initialCount = sa[0].fullPartitionCount;\n",
    "        while (i < sa.length && sa[i].fullPartitionCount == initialCount) i++;\n",
    "        System.out.format(\"\\tSplit: %s, start: %s, count: %s\\n\", \n",
    "                    i-1, sa[i-1].fullPartitionStartId, sa[i-1].fullPartitionCount); \n",
    "        if (i < sa.length) {\n",
    "            System.out.format(\"\\tSplit: %s, start: %s, count: %s\\n\", \n",
    "                        i, sa[i].fullPartitionStartId, sa[i].fullPartitionCount);\n",
    "            i = sa.length-1;\n",
    "            System.out.format(\"\\tSplit: %s, start: %s, count: %s\\n\", \n",
    "                        i, sa[i].fullPartitionStartId, sa[i].fullPartitionCount);            \n",
    "        }\n",
    "    } else {\n",
    "        int i = 0;\n",
    "        System.out.format(\"\\tSplit: %s, partial: %s, first: %s, second: %s, modulo: %s\\n\", \n",
    "            i, sa[i].partialPartitionId, sa[i].firstSubpartition, sa[i].secondSubpartition, sa[i].subPartitonModuloFactor); \n",
    "        Integer initialSecondPartition = sa[0].secondSubpartition;\n",
    "        while (i < sa.length && (initialSecondPartition == null || sa[i].secondSubpartition != null)) i++;\n",
    "        System.out.format(\"\\tSplit: %s, partial: %s, first: %s, second: %s, modulo: %s\\n\", \n",
    "            i-1, sa[i-1].partialPartitionId, sa[i-1].firstSubpartition, sa[i-1].secondSubpartition, sa[i-1].subPartitonModuloFactor); \n",
    "        if (i < sa.length) {\n",
    "            System.out.format(\"\\tSplit: %s, partial: %s, first: %s, second: %s, modulo: %s\\n\", \n",
    "                i, sa[i].partialPartitionId, sa[i].firstSubpartition, sa[i].secondSubpartition, sa[i].subPartitonModuloFactor); \n",
    "            i = sa.length-1;\n",
    "            System.out.format(\"\\tSplit: %s, partial: %s, first: %s, second: %s, modulo: %s\\n\", \n",
    "                i, sa[i].partialPartitionId, sa[i].firstSubpartition, sa[i].secondSubpartition, sa[i].subPartitonModuloFactor); \n",
    "        }\n",
    "    }    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Query Framework\n",
    "The parallel processing test framework works as follows:\n",
    "- Create N splits. This can be varied over a wide range such as 1-50K, along with the type parameter over AtLeast, AtMost, and Exact values.\n",
    "- Spawn W worker threads. This can be varied over a wide range such as 1-10K or more if the container allows it. All threads start processing splits at the same time, and the main thread waits until all threads finish.\n",
    "- A worker executes a loop:\n",
    "    - While threr is an unprocessed split available:\n",
    "    - Get a split from the available splits.\n",
    "    - Process the split:\n",
    "        - While there are more records to be processed in the split, in sync and async mode:\n",
    "        - Execute a query to retrieve max-records. The query can be a primary-index query or a secondary-index query, and with or without a fiter expression.\n",
    "        - Process the chunk (count the records, and compute the aggregate sum).\n",
    "- The total record count and aggregate sum is printed out at the end, which should be the same for a given query and filter expression\n",
    "\n",
    "The code below implements the parallel processing framework that allows interesting parameters to be selected for each run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global parameters\n",
    "The following parameters are implemented as global variables for convenience. They can be set to appropriate desired values before a run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Global parameters - set to specific values later before a run\n",
    "int ProcessingMode;     // set to PROCESSING_MODE_SYNC or PROCESSING_MODE_ASYNC\n",
    "int QueryType;          // PRIMARY_INDEX_QUERY or SECONDARY_INDEX_QUERY\n",
    "int QueryFilter;        // QUERY_FILTER_NONE or QUERY_FILTER_INCLUDE\n",
    "int ChunkSize;          // max number of records retrieved in a chunk\n",
    "Filter SecondaryIndexQueryPredicate; // sindex query predicate, used when QueryType = SECONDARY_INDEX_QUERY\n",
    "Exp IncludeQueryFilterExp; // filter expression, used when QueryFilter = QUERY_FILTER_INCLUDE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Implementation of the parallel query framework\n",
    "\n",
    "AtomicInteger recCount = new AtomicInteger();    // total number of records processed\n",
    "AtomicLong recSum = new AtomicLong();            // sum across all records\n",
    "AtomicInteger workerId = new AtomicInteger();    // worker id\n",
    "AtomicInteger nextSplit = new AtomicInteger();   // next unclaimed split\n",
    "CountDownLatch startLineLatch;                   // forces all workers to start at the same time\n",
    "\n",
    "Statement stmt = new Statement();\n",
    "stmt.setNamespace(Namespace);\n",
    "stmt.setSetName(Set);\n",
    "stmt.setBinNames(\"bin1\", \"bin2\");\n",
    "\n",
    "class Worker extends Thread {\n",
    "    static SplitAssignment[] assignments; // splits to be processed\n",
    "    static int[] workerRecCounts;         // records processed by each worker\n",
    "        \n",
    "    @Override public void run(){\n",
    "        int myId = workerId.getAndIncrement();    \n",
    "        try {\n",
    "            startLineLatch.countDown(); // count down\n",
    "            startLineLatch.await();     // all workers start when count reaches zero\n",
    "        }\n",
    "        catch (Exception e) {\n",
    "           System.out.format(\"%s\", e);\n",
    "        }\n",
    "        //System.out.println(Thread.currentThread().getName()\n",
    "        //            + \": \" + myId);\n",
    "        int numSplits = Worker.assignments.length;\n",
    "        // loop to get the next available split until all splits are gone\n",
    "        for (int split = nextSplit.getAndIncrement(); split < numSplits; split = nextSplit.getAndIncrement()) {\n",
    "            SplitAssignment sa = Worker.assignments[split]; // split to process\n",
    "            PartitionFilter pFilter;\n",
    "            QueryPolicy qPolicy = new QueryPolicy(client.queryPolicyDefault);\n",
    "            qPolicy.filterExp = null;\n",
    "            // define the query partition filter\n",
    "            if (sa.isFullPartitionAssignment) { // if full partitions, assign the range\n",
    "                pFilter = PartitionFilter.range(sa.fullPartitionStartId, sa.fullPartitionCount);\n",
    "                if (QueryFilter == QUERY_FILTER_INCLUDE) { \n",
    "                    qPolicy.filterExp = Exp.build(IncludeQueryFilterExp); //  filter expression is specified in policy\n",
    "                }\n",
    "            } else { // if partial partitions, define the digest-modulo filter expression\n",
    "                int moduloFactor = sa.subPartitonModuloFactor;\n",
    "                pFilter = PartitionFilter.id(sa.partialPartitionId); \n",
    "                Exp firstSubpartitionExp = Exp.eq(Exp.digestModulo(moduloFactor), Exp.val(sa.firstSubpartition));\n",
    "                Exp subpartitionExp = firstSubpartitionExp;\n",
    "                if (sa.secondSubpartition != null) { // a split has a second sub-partition\n",
    "                    subpartitionExp = Exp.or(\n",
    "                                        firstSubpartitionExp, \n",
    "                                        Exp.eq(Exp.digestModulo(moduloFactor), Exp.val(sa.secondSubpartition)));\n",
    "                }\n",
    "                Exp queryFilterExp = subpartitionExp;\n",
    "                if (QueryFilter == QUERY_FILTER_INCLUDE) { // AND with the query's filter expression\n",
    "                    queryFilterExp = Exp.and(\n",
    "                                        subpartitionExp,\n",
    "                                        IncludeQueryFilterExp);\n",
    "                }\n",
    "                qPolicy.filterExp = Exp.build(queryFilterExp); //  filter expression is specified in policy\n",
    "            }\n",
    "            stmt.setMaxRecords(ChunkSize);  // chunked retrieval of query results \n",
    "            stmt.setFilter(null);            // this query filter is null for a primary-index query\n",
    "            if (QueryType == SECONDARY_INDEX_QUERY) {\n",
    "                stmt.setFilter(SecondaryIndexQueryPredicate); // set secondary-index query predicate here\n",
    "            }\n",
    "            if (ProcessingMode == PROCESSING_MODE_SYNC) { // select the processing mode\n",
    "                Worker.workerRecCounts[myId] += this.processSync(qPolicy, stmt, pFilter); \n",
    "            } else {\n",
    "                Worker.workerRecCounts[myId] += this.processAsync(qPolicy, stmt, pFilter);\n",
    "            }\n",
    "            try {\n",
    "                Thread.sleep(1); // allow other threads to run\n",
    "            }\n",
    "            catch (Exception e) {\n",
    "               System.out.format(\"%s\", e);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    int processSync(QueryPolicy qPolicy, Statement stmt, PartitionFilter pFilter) {\n",
    "        int splitRecs = 0; // tracks number of records in this split\n",
    "        long splitSum = 0; // tracks sum of records in this split\n",
    "        // retrieve chunks of records in a loop\n",
    "        while (! pFilter.isDone()) {\n",
    "            RecordSet rs = client.queryPartitions(qPolicy, stmt, pFilter);\n",
    "            try {\n",
    "                while (rs.next()) {\n",
    "                    splitRecs++;\n",
    "                    Record rec = rs.getRecord();\n",
    "                    splitSum += (long)rec.bins.get(\"bin1\");             \n",
    "                }\n",
    "                //System.out.println(\"Records returned: \" + count);\n",
    "            }\n",
    "            finally {\n",
    "                rs.close();\n",
    "            }\n",
    "        }\n",
    "        recCount.addAndGet(splitRecs);\n",
    "        recSum.addAndGet(splitSum);\n",
    "        return splitRecs;\n",
    "    }\n",
    "        \n",
    "    int processAsync(QueryPolicy qPolicy, Statement stmt, PartitionFilter pFilter) {\n",
    "        AtomicInteger splitRecs = new AtomicInteger(0);\n",
    "        // Query all pages of records.\n",
    "        while (! pFilter.isDone()) {\n",
    "            // query monitor to await/notify completion of each chunk\n",
    "            Monitor queryMonitor = new Monitor();\n",
    "            // submit async operation with throttle by waiting for an available slot\n",
    "            EventLoop eventLoop = eventLoops.next();\n",
    "            int eventLoopIndex = eventLoop.getIndex();\n",
    "            if (throttles.waitForSlot(eventLoopIndex, 1)) { \n",
    "                try {\n",
    "                    client.queryPartitions(eventLoop, new RecordSequenceListener() {\n",
    "                            public void onRecord(Key key, Record record) throws AerospikeException {\n",
    "                                splitRecs.incrementAndGet();\n",
    "                                recSum.addAndGet((long)record.bins.get(\"bin1\"));\n",
    "                             }\n",
    "                             \n",
    "                            public void onSuccess() {\n",
    "                                throttles.addSlot(eventLoopIndex, 1);\n",
    "                                queryMonitor.notifyComplete();\n",
    "                            }\n",
    "\n",
    "                            public void onFailure(AerospikeException e) {\n",
    "                                throttles.addSlot(eventLoopIndex, 1);\n",
    "                                System.out.format(\"Error: query failed with exception - %s\", e);\n",
    "                                queryMonitor.notifyComplete();\n",
    "                            }                    \n",
    "                        }, \n",
    "                        qPolicy, stmt, pFilter);\n",
    "                }\n",
    "                catch (Exception e) {\n",
    "                   System.out.format(\"Error: exception in record sequence listener - %s\\n\", e.getMessage());\n",
    "                }\n",
    "            }\n",
    "            queryMonitor.waitTillComplete();\n",
    "        }\n",
    "        int count = splitRecs.get();\n",
    "        recCount.addAndGet(count);\n",
    "        return count;\n",
    "    }\n",
    "}\n",
    "\n",
    "void workerSummary() {\n",
    "    System.out.print(\"Records by worker (~50 worker sample): \");\n",
    "    float step = (Worker.workerRecCounts.length-1)/50;\n",
    "    for (int i = 0; i < Worker.workerRecCounts.length; i += 1+step) {\n",
    "        System.out.format(\"%d:%d \", i, Worker.workerRecCounts[i]);\n",
    "    }\n",
    "    System.out.println(\"\");\n",
    "}\n",
    "\n",
    "void processSplits(SplitAssignment[] splitAssignments, int numWorkers) {\n",
    "    System.out.format(\"%d worker threads.\\n\", numWorkers);\n",
    "    Worker.assignments = splitAssignments;\n",
    "    Worker.workerRecCounts = new int[numWorkers];\n",
    "    workerId.set(0);\n",
    "    nextSplit.set(0);\n",
    "    recCount.set(0);\n",
    "    recSum.set(0); \n",
    "    startLineLatch = new CountDownLatch(numWorkers);\n",
    "    List<Worker> workers = new ArrayList<>();\n",
    "    for (int i = 0; i < numWorkers; i++) {\n",
    "        Worker worker = new Worker();\n",
    "        worker.setName(\"Worker \" + i);\n",
    "        workers.add(worker);\n",
    "        worker.start();\n",
    "    }\n",
    "    long startTime = System.currentTimeMillis();\n",
    "    try {\n",
    "        for (Worker worker: workers) {\n",
    "            worker.join();\n",
    "        }\n",
    "    }\n",
    "    catch (Exception e) {\n",
    "       System.out.format(\"%s\", e);\n",
    "    }\n",
    "    long endTime = System.currentTimeMillis();\n",
    "    System.out.format(\"Record count is %d, sum is %d.\\n\", recCount.get(), recSum.get());\n",
    "    System.out.println(\"That took \" + (endTime - startTime)/1000 + \" seconds.\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Parallel Queries with Interesting Parameter Variations\n",
    "The key things to note are:\n",
    "- Split assignments - a summary can be printed out optionally as seen below.\n",
    "- Number of records and aggregated sum should be the same for the same query/filter setting, confirming all records are processed correctly.\n",
    "- Performance indicated by the time it took to execute a query\n",
    "- Distribution of records processed by worker - a summary can be printed out optionally as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "// set the base global parameter values - can be changed here or before a run in the cells below\n",
    "ProcessingMode = PROCESSING_MODE_SYNC;\n",
    "QueryType = PRIMARY_INDEX_QUERY;\n",
    "QueryFilter = QUERY_FILTER_NONE;\n",
    "ChunkSize = 20;\n",
    "\n",
    "// the following filter expression chooses records with even values of bin1 - CAN CHANGE TO A DIFFERENT EXPRESSION\n",
    "//    used when QueryFilter = QUERY_FILTER_INCLUDE\n",
    "IncludeQueryFilterExp = Exp.eq(Exp.mod(Exp.intBin(\"bin1\"), Exp.val(2)), Exp.val(0));\n",
    "\n",
    "// the following query predicate is a range filter for records with 50001 <= bin1 <= 100000 - CAN CHANGE TO A DIFFERENT QUERY PREDICATE\n",
    "//    used when QueryType = SECONDARY_INDEX_QUERY\n",
    "SecondaryIndexQueryPredicate = Filter.range(\"bin1\", 50001, 100000);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Varying number of splits and split types\n",
    "Vary the number of splits from 1-50000 acoss all split types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requested splits: 2, type: MIN_NUM_SPLITS\n",
      "2 splits: \n",
      "\tSplit: 0, start: 0, count: 2048\n",
      "\tSplit: 1, start: 2048, count: 2048\n",
      "100 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 40 seconds.\n",
      "\n",
      "Requested splits: 10, type: MIN_NUM_SPLITS\n",
      "16 splits: \n",
      "\tSplit: 0, start: 0, count: 256\n",
      "\tSplit: 15, start: 3840, count: 256\n",
      "100 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 6 seconds.\n",
      "\n",
      "Requested splits: 100, type: EXACT_NUM_SPLITS\n",
      "100 splits: \n",
      "\tSplit: 0, start: 0, count: 41\n",
      "\tSplit: 95, start: 3895, count: 41\n",
      "\tSplit: 96, start: 3936, count: 40\n",
      "\tSplit: 99, start: 4056, count: 40\n",
      "100 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 3 seconds.\n",
      "Records by worker (~50 worker sample): 0:991 2:1046 4:1014 6:1047 8:999 10:1000 12:1000 14:997 16:948 18:1007 20:1017 22:990 24:1015 26:999 28:1005 30:1050 32:953 34:985 36:964 38:970 40:959 42:1041 44:993 46:1015 48:906 50:963 52:975 54:993 56:958 58:1023 60:1021 62:956 64:1014 66:947 68:944 70:990 72:1032 74:948 76:977 78:962 80:951 82:1041 84:1020 86:1067 88:1070 90:1006 92:996 94:962 96:1076 98:976 \n",
      "\n",
      "Requested splits: 1000, type: MAX_NUM_SPLITS\n",
      "512 splits: \n",
      "\tSplit: 0, start: 0, count: 8\n",
      "\tSplit: 511, start: 4088, count: 8\n",
      "100 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 2 seconds.\n",
      "Records by worker (~50 worker sample): 0:979 2:1161 4:986 6:995 8:964 10:1022 12:992 14:1006 16:980 18:962 20:1009 22:1048 24:794 26:1008 28:1011 30:1019 32:925 34:770 36:968 38:959 40:970 42:991 44:939 46:979 48:986 50:950 52:953 54:991 56:996 58:918 60:998 62:991 64:1200 66:1001 68:1011 70:1013 72:965 74:956 76:958 78:966 80:973 82:941 84:1148 86:980 88:946 90:937 92:948 94:983 96:987 98:949 \n",
      "\n",
      "Requested splits: 5000, type: MAX_NUM_SPLITS\n",
      "4096 splits: \n",
      "\tSplit: 0, start: 0, count: 1\n",
      "\tSplit: 4095, start: 4095, count: 1\n",
      "100 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 3 seconds.\n",
      "Records by worker (~50 worker sample): 0:945 2:962 4:965 6:1069 8:966 10:943 12:1077 14:1016 16:1088 18:989 20:1052 22:957 24:909 26:1002 28:906 30:909 32:975 34:1050 36:1106 38:1014 40:1023 42:1042 44:897 46:958 48:1000 50:954 52:903 54:854 56:857 58:1105 60:1014 62:1067 64:1023 66:1099 68:989 70:1022 72:944 74:1056 76:1034 78:928 80:997 82:916 84:949 86:1033 88:1056 90:929 92:929 94:1070 96:992 98:1015 \n",
      "\n",
      "Requested splits: 10000, type: EXACT_NUM_SPLITS\n",
      "10000 splits: \n",
      "\tSplit: 0, partial: 0, first: 0, second: 1, modulo: 3\n",
      "\tSplit: 2287, partial: 2287, first: 0, second: 1, modulo: 3\n",
      "\tSplit: 2288, partial: 0, first: 2, second: null, modulo: 3\n",
      "\tSplit: 9999, partial: 4095, first: 2, second: null, modulo: 3\n",
      "100 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 4 seconds.\n",
      "Records by worker (~50 worker sample): 0:1083 2:1003 4:982 6:1079 8:997 10:1016 12:994 14:1046 16:1006 18:952 20:971 22:1094 24:1015 26:1005 28:1115 30:976 32:920 34:919 36:942 38:966 40:951 42:972 44:976 46:998 48:1019 50:1000 52:959 54:1016 56:973 58:983 60:987 62:947 64:960 66:984 68:1032 70:1053 72:1033 74:1070 76:1020 78:1012 80:980 82:1007 84:981 86:1000 88:934 90:991 92:1132 94:1035 96:999 98:969 \n",
      "\n",
      "Requested splits: 50000, type: MAX_NUM_SPLITS\n",
      "49152 splits: \n",
      "\tSplit: 0, partial: 0, first: 0, second: null, modulo: 12\n",
      "\tSplit: 49151, partial: 4095, first: 11, second: null, modulo: 12\n",
      "100 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 21 seconds.\n",
      "Records by worker (~50 worker sample): 0:1006 2:978 4:974 6:1002 8:971 10:978 12:1015 14:990 16:954 18:987 20:996 22:910 24:989 26:1096 28:986 30:1041 32:978 34:1013 36:1030 38:969 40:1058 42:1015 44:967 46:956 48:1006 50:1020 52:1044 54:1024 56:998 58:1018 60:980 62:1017 64:1007 66:1033 68:973 70:1007 72:971 74:1043 76:1034 78:1004 80:989 82:1068 84:1035 86:970 88:1038 90:986 92:960 94:960 96:1057 98:996 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "int NumWorkers = 100;\n",
    "\n",
    "System.out.format(\"Requested splits: %d, type: %s\\n\", 2, \"MIN_NUM_SPLITS\");\n",
    "SplitAssignment[] splitAssignments = assignSplits(2, MIN_NUM_SPLITS);\n",
    "assignmentSummary(splitAssignments);\n",
    "processSplits(splitAssignments, NumWorkers);\n",
    "System.out.println();\n",
    "\n",
    "System.out.format(\"Requested splits: %d, type: %s\\n\", 10, \"MIN_NUM_SPLITS\");\n",
    "splitAssignments = assignSplits(10, MIN_NUM_SPLITS);\n",
    "assignmentSummary(splitAssignments);\n",
    "processSplits(splitAssignments, NumWorkers);\n",
    "System.out.println();\n",
    "\n",
    "System.out.format(\"Requested splits: %d, type: %s\\n\", 100, \"EXACT_NUM_SPLITS\");\n",
    "splitAssignments = assignSplits(100, EXACT_NUM_SPLITS);\n",
    "assignmentSummary(splitAssignments);\n",
    "processSplits(splitAssignments, NumWorkers);\n",
    "workerSummary();\n",
    "System.out.println();\n",
    "\n",
    "System.out.format(\"Requested splits: %d, type: %s\\n\", 1000, \"MAX_NUM_SPLITS\");\n",
    "splitAssignments = assignSplits(1000, MAX_NUM_SPLITS);\n",
    "assignmentSummary(splitAssignments);\n",
    "processSplits(splitAssignments, NumWorkers);\n",
    "workerSummary();\n",
    "System.out.println();\n",
    "\n",
    "System.out.format(\"Requested splits: %d, type: %s\\n\", 5000, \"MAX_NUM_SPLITS\");\n",
    "splitAssignments = assignSplits(5000, MAX_NUM_SPLITS);\n",
    "assignmentSummary(splitAssignments);\n",
    "processSplits(splitAssignments, NumWorkers);\n",
    "workerSummary();\n",
    "System.out.println();\n",
    "\n",
    "System.out.format(\"Requested splits: %d, type: %s\\n\", 10000, \"EXACT_NUM_SPLITS\");\n",
    "splitAssignments = assignSplits(10000, EXACT_NUM_SPLITS);\n",
    "assignmentSummary(splitAssignments);\n",
    "processSplits(splitAssignments, NumWorkers);\n",
    "workerSummary();\n",
    "System.out.println();\n",
    "\n",
    "System.out.format(\"Requested splits: %d, type: %s\\n\", 50000, \"MAX_NUM_SPLITS\");\n",
    "splitAssignments = assignSplits(50000, MAX_NUM_SPLITS);\n",
    "assignmentSummary(splitAssignments);\n",
    "processSplits(splitAssignments, NumWorkers);\n",
    "workerSummary();\n",
    "System.out.println();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Varying number of workers in sync mode\n",
    "Vary the number of workers from 10 to 5000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 splits: \n",
      "\tSplit: 0, partial: 0, first: 0, second: 1, modulo: 3\n",
      "\tSplit: 2287, partial: 2287, first: 0, second: 1, modulo: 3\n",
      "\tSplit: 2288, partial: 0, first: 2, second: null, modulo: 3\n",
      "\tSplit: 9999, partial: 4095, first: 2, second: null, modulo: 3\n",
      "10 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 4 seconds.\n",
      "Records by worker (~50 worker sample): 0:10155 1:10143 2:9999 3:10039 4:9923 5:10316 6:9852 7:9979 8:9899 9:9695 \n",
      "\n",
      "100 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 4 seconds.\n",
      "Records by worker (~50 worker sample): 0:973 2:1054 4:934 6:1102 8:1012 10:901 12:1045 14:966 16:1121 18:1063 20:1063 22:924 24:950 26:894 28:989 30:971 32:987 34:966 36:1067 38:1088 40:1092 42:981 44:1032 46:1051 48:1036 50:956 52:1056 54:989 56:900 58:882 60:928 62:987 64:991 66:1134 68:1063 70:941 72:1092 74:1020 76:1083 78:1110 80:895 82:879 84:940 86:1012 88:1085 90:1128 92:1049 94:909 96:962 98:960 \n",
      "\n",
      "1000 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 5 seconds.\n",
      "Records by worker (~50 worker sample): 0:133 20:144 40:121 60:129 80:101 100:114 120:98 140:111 160:114 180:101 200:107 220:103 240:105 260:101 280:103 300:115 320:90 340:110 360:95 380:89 400:92 420:102 440:106 460:82 480:93 500:86 520:117 540:114 560:98 580:120 600:84 620:90 640:102 660:82 680:107 700:96 720:92 740:111 760:104 780:106 800:91 820:96 840:87 860:118 880:101 900:101 920:98 940:90 960:99 980:87 \n",
      "\n",
      "5000 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 11 seconds.\n",
      "Records by worker (~50 worker sample): 0:48 100:43 200:48 300:36 400:17 500:38 600:35 700:25 800:22 900:37 1000:27 1100:31 1200:22 1300:19 1400:17 1500:26 1600:69 1700:33 1800:33 1900:30 2000:5 2100:5 2200:8 2300:8 2400:8 2500:11 2600:3 2700:6 2800:6 2900:6 3000:7 3100:7 3200:10 3300:7 3400:6 3500:12 3600:35 3700:5 3800:14 3900:6 4000:40 4100:8 4200:10 4300:7 4400:10 4500:5 4600:11 4700:12 4800:7 4900:20 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "int ReqSplits = 10000;\n",
    "\n",
    "SplitAssignment[] splitAssignments = assignSplits(ReqSplits, EXACT_NUM_SPLITS);\n",
    "assignmentSummary(splitAssignments);\n",
    "processSplits(splitAssignments, 10);\n",
    "workerSummary();\n",
    "System.out.println();\n",
    "\n",
    "splitAssignments = assignSplits(ReqSplits, EXACT_NUM_SPLITS);\n",
    "//assignmentSummary(splitAssignments);\n",
    "processSplits(splitAssignments, 100);\n",
    "workerSummary();\n",
    "System.out.println();\n",
    "\n",
    "splitAssignments = assignSplits(ReqSplits, EXACT_NUM_SPLITS);\n",
    "//assignmentSummary(splitAssignments);\n",
    "processSplits(splitAssignments, 1000);\n",
    "workerSummary();\n",
    "System.out.println();\n",
    "\n",
    "splitAssignments = assignSplits(ReqSplits, EXACT_NUM_SPLITS);\n",
    "//assignmentSummary(splitAssignments);\n",
    "processSplits(splitAssignments, 5000);\n",
    "workerSummary();\n",
    "System.out.println();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Varying number of workers in sync and async mode\n",
    "Vary the number of workers from 10 to 5000 in sync and async mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing mode: SYNC\n",
      "10000 splits: \n",
      "\tSplit: 0, partial: 0, first: 0, second: 1, modulo: 3\n",
      "\tSplit: 2287, partial: 2287, first: 0, second: 1, modulo: 3\n",
      "\tSplit: 2288, partial: 0, first: 2, second: null, modulo: 3\n",
      "\tSplit: 9999, partial: 4095, first: 2, second: null, modulo: 3\n",
      "10 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 6 seconds.\n",
      "Records by worker (~50 worker sample): 0:9974 1:10131 2:10240 3:10020 4:10041 5:9992 6:10007 7:10025 8:9861 9:9709 \n",
      "\n",
      "Processing mode: ASYNC\n",
      "10 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 3 seconds.\n",
      "Records by worker (~50 worker sample): 0:10025 1:9966 2:9847 3:10223 4:10167 5:9934 6:9956 7:9914 8:9845 9:10123 \n",
      "\n",
      "Processing mode: SYNC\n",
      "100 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 5 seconds.\n",
      "Records by worker (~50 worker sample): 0:1019 2:990 4:1064 6:982 8:986 10:999 12:1025 14:1021 16:965 18:1004 20:1014 22:1015 24:968 26:997 28:997 30:1062 32:1006 34:973 36:1017 38:970 40:977 42:1008 44:991 46:967 48:979 50:1007 52:1054 54:986 56:1059 58:977 60:988 62:1010 64:1000 66:1010 68:1003 70:972 72:998 74:937 76:971 78:972 80:1009 82:993 84:992 86:1013 88:1043 90:985 92:1007 94:963 96:1014 98:1052 \n",
      "\n",
      "Processing mode: ASYNC\n",
      "100 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 3 seconds.\n",
      "Records by worker (~50 worker sample): 0:1032 2:985 4:1077 6:1019 8:949 10:1040 12:1039 14:1114 16:1072 18:1021 20:1006 22:914 24:1028 26:1121 28:997 30:1045 32:1203 34:1101 36:910 38:857 40:951 42:985 44:1028 46:915 48:974 50:958 52:915 54:1048 56:1066 58:1075 60:976 62:1027 64:1070 66:979 68:1079 70:1035 72:873 74:856 76:1059 78:952 80:967 82:986 84:1021 86:1104 88:1022 90:1023 92:1116 94:942 96:1058 98:1059 \n",
      "\n",
      "Processing mode: SYNC\n",
      "1000 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 5 seconds.\n",
      "Records by worker (~50 worker sample): 0:108 20:98 40:121 60:94 80:122 100:104 120:110 140:100 160:85 180:80 200:93 220:114 240:96 260:91 280:73 300:99 320:102 340:133 360:95 380:100 400:95 420:103 440:125 460:128 480:93 500:120 520:103 540:109 560:90 580:102 600:92 620:100 640:96 660:112 680:97 700:112 720:70 740:96 760:82 780:96 800:88 820:87 840:103 860:92 880:94 900:73 920:74 940:90 960:100 980:93 \n",
      "\n",
      "Processing mode: ASYNC\n",
      "1000 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 3 seconds.\n",
      "Records by worker (~50 worker sample): 0:106 20:124 40:144 60:106 80:104 100:154 120:101 140:123 160:75 180:94 200:95 220:113 240:76 260:99 280:87 300:77 320:104 340:83 360:80 380:89 400:96 420:109 440:88 460:107 480:136 500:106 520:61 540:87 560:101 580:110 600:91 620:50 640:99 660:96 680:83 700:97 720:146 740:104 760:78 780:104 800:84 820:81 840:90 860:104 880:93 900:63 920:60 940:96 960:114 980:77 \n",
      "\n",
      "Processing mode: SYNC\n",
      "5000 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 7 seconds.\n",
      "Records by worker (~50 worker sample): 0:57 100:29 200:28 300:32 400:47 500:27 600:29 700:26 800:22 900:24 1000:25 1100:40 1200:27 1300:24 1400:15 1500:20 1600:32 1700:20 1800:18 1900:25 2000:20 2100:20 2200:16 2300:22 2400:12 2500:26 2600:10 2700:20 2800:19 2900:21 3000:20 3100:16 3200:19 3300:13 3400:27 3500:14 3600:24 3700:13 3800:12 3900:21 4000:14 4100:19 4200:13 4300:6 4400:9 4500:9 4600:9 4700:7 4800:16 4900:12 \n",
      "\n",
      "Processing mode: ASYNC\n",
      "5000 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 5 seconds.\n",
      "Records by worker (~50 worker sample): 0:34 100:33 200:30 300:44 400:43 500:34 600:37 700:56 800:30 900:37 1000:23 1100:22 1200:32 1300:45 1400:50 1500:29 1600:21 1700:27 1800:15 1900:33 2000:36 2100:40 2200:11 2300:9 2400:22 2500:8 2600:20 2700:10 2800:24 2900:17 3000:9 3100:23 3200:15 3300:12 3400:13 3500:21 3600:12 3700:3 3800:13 3900:20 4000:14 4100:16 4200:4 4300:7 4400:6 4500:10 4600:10 4700:6 4800:8 4900:19 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "int ReqSplits = 10000;\n",
    "\n",
    "ProcessingMode = PROCESSING_MODE_SYNC;\n",
    "System.out.format(\"Processing mode: SYNC\\n\");\n",
    "SplitAssignment[] splitAssignments = assignSplits(ReqSplits, EXACT_NUM_SPLITS);\n",
    "assignmentSummary(splitAssignments);\n",
    "processSplits(splitAssignments, 10);\n",
    "workerSummary();\n",
    "System.out.println();\n",
    "\n",
    "ProcessingMode = PROCESSING_MODE_ASYNC;\n",
    "System.out.format(\"Processing mode: ASYNC\\n\");\n",
    "splitAssignments = assignSplits(ReqSplits, EXACT_NUM_SPLITS);\n",
    "//assignmentSummary(splitAssignments);\n",
    "processSplits(splitAssignments, 10);\n",
    "workerSummary();\n",
    "System.out.println();\n",
    "\n",
    "ProcessingMode = PROCESSING_MODE_SYNC;\n",
    "System.out.format(\"Processing mode: SYNC\\n\");\n",
    "SplitAssignment[] splitAssignments = assignSplits(ReqSplits, EXACT_NUM_SPLITS);\n",
    "//assignmentSummary(splitAssignments);\n",
    "processSplits(splitAssignments, 100);\n",
    "workerSummary();\n",
    "System.out.println();\n",
    "\n",
    "ProcessingMode = PROCESSING_MODE_ASYNC;\n",
    "System.out.format(\"Processing mode: ASYNC\\n\");\n",
    "splitAssignments = assignSplits(ReqSplits, EXACT_NUM_SPLITS);\n",
    "//assignmentSummary(splitAssignments);\n",
    "processSplits(splitAssignments, 100);\n",
    "workerSummary();\n",
    "System.out.println();\n",
    "\n",
    "ProcessingMode = PROCESSING_MODE_SYNC;\n",
    "System.out.format(\"Processing mode: SYNC\\n\");\n",
    "SplitAssignment[] splitAssignments = assignSplits(ReqSplits, EXACT_NUM_SPLITS);\n",
    "//assignmentSummary(splitAssignments);\n",
    "processSplits(splitAssignments, 1000);\n",
    "workerSummary();\n",
    "System.out.println();\n",
    "\n",
    "ProcessingMode = PROCESSING_MODE_ASYNC;\n",
    "System.out.format(\"Processing mode: ASYNC\\n\");\n",
    "splitAssignments = assignSplits(ReqSplits, EXACT_NUM_SPLITS);\n",
    "//assignmentSummary(splitAssignments);\n",
    "processSplits(splitAssignments, 1000);\n",
    "workerSummary();\n",
    "System.out.println();\n",
    "\n",
    "ProcessingMode = PROCESSING_MODE_SYNC;\n",
    "System.out.format(\"Processing mode: SYNC\\n\");\n",
    "SplitAssignment[] splitAssignments = assignSplits(ReqSplits, EXACT_NUM_SPLITS);\n",
    "//assignmentSummary(splitAssignments);\n",
    "processSplits(splitAssignments, 5000);\n",
    "workerSummary();\n",
    "System.out.println();\n",
    "\n",
    "ProcessingMode = PROCESSING_MODE_ASYNC;\n",
    "System.out.format(\"Processing mode: ASYNC\\n\");\n",
    "splitAssignments = assignSplits(ReqSplits, EXACT_NUM_SPLITS);\n",
    "//assignmentSummary(splitAssignments);\n",
    "processSplits(splitAssignments, 5000);\n",
    "workerSummary();\n",
    "System.out.println();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Varying query type and filter\n",
    "Primary-index and sexondary-index queries with and without a filter expression. Note the default secondary-index query predicate will process half the records and yield half the sum value. The default filter expression, in turn, will also process half the records and yield half the sum of the filterless query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary-index query with no filter\n",
      "1000 splits: \n",
      "\tSplit: 0, start: 0, count: 5\n",
      "\tSplit: 95, start: 475, count: 5\n",
      "\tSplit: 96, start: 480, count: 4\n",
      "\tSplit: 999, start: 4092, count: 4\n",
      "100 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 2 seconds.\n",
      "Records by worker (~50 worker sample): 0:1035 2:1148 4:1074 6:1186 8:1024 10:1020 12:919 14:827 16:1105 18:947 20:1318 22:888 24:974 26:867 28:801 30:841 32:899 34:1045 36:1025 38:914 40:1176 42:808 44:985 46:902 48:1485 50:911 52:980 54:952 56:1009 58:716 60:861 62:1169 64:1226 66:810 68:1105 70:725 72:901 74:841 76:1064 78:1062 80:1070 82:970 84:950 86:1037 88:878 90:1104 92:961 94:955 96:821 98:1029 \n",
      "\n",
      "Primary-index query with filter expression\n",
      "100 worker threads.\n",
      "Record count is 50000, sum is 2500050000.\n",
      "That took 1 seconds.\n",
      "\n",
      "Secondary-index query with no filter\n",
      "100 worker threads.\n",
      "Record count is 50540, sum is 2526213401.\n",
      "That took 1 seconds.\n",
      "\n",
      "Secondary-index query with filter expression\n",
      "100 worker threads.\n",
      "Record count is 25000, sum is 1250025000.\n",
      "That took 0 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// the following filter expression chooses records with even values of bin1 - CAN CHANGE TO A DIFFERENT EXPRESSION\n",
    "//    used when QueryFilter = QUERY_FILTER_INCLUDE\n",
    "IncludeQueryFilterExp = Exp.eq(Exp.mod(Exp.intBin(\"bin1\"), Exp.val(2)), Exp.val(0));\n",
    "\n",
    "// the following query predicate is a range filter for records with 50001 <= bin1 <= 100000 - CAN CHANGE TO A DIFFERENT QUERY PREDICATE\n",
    "//    used when QueryType = SECONDARY_INDEX_QUERY\n",
    "SecondaryIndexQueryPredicate = Filter.range(\"bin1\", 25001, 75000);\n",
    "\n",
    "int ReqSplits = 1000;\n",
    "int NumWorkers = 100;\n",
    "ProcessingMode = PROCESSING_MODE_SYNC;\n",
    "\n",
    "QueryType = PRIMARY_INDEX_QUERY;\n",
    "QueryFilter = QUERY_FILTER_NONE;\n",
    "System.out.format(\"Primary-index query with no filter\\n\");\n",
    "splitAssignments = assignSplits(ReqSplits, EXACT_NUM_SPLITS);\n",
    "assignmentSummary(splitAssignments);\n",
    "processSplits(splitAssignments, NumWorkers);\n",
    "workerSummary();\n",
    "System.out.println();\n",
    "\n",
    "QueryType = PRIMARY_INDEX_QUERY;\n",
    "QueryFilter = QUERY_FILTER_INCLUDE;\n",
    "System.out.format(\"Primary-index query with filter expression\\n\");\n",
    "splitAssignments = assignSplits(ReqSplits, EXACT_NUM_SPLITS);\n",
    "//assignmentSummary(splitAssignments);\n",
    "processSplits(splitAssignments, NumWorkers);\n",
    "//workerSummary();\n",
    "System.out.println();\n",
    "\n",
    "QueryType = SECONDARY_INDEX_QUERY;\n",
    "QueryFilter = QUERY_FILTER_NONE;\n",
    "System.out.format(\"Secondary-index query with no filter\\n\");\n",
    "splitAssignments = assignSplits(ReqSplits, EXACT_NUM_SPLITS);\n",
    "//assignmentSummary(splitAssignments);\n",
    "processSplits(splitAssignments, NumWorkers);\n",
    "//workerSummary();\n",
    "System.out.println();\n",
    "\n",
    "QueryType = SECONDARY_INDEX_QUERY;\n",
    "QueryFilter = QUERY_FILTER_INCLUDE;\n",
    "System.out.format(\"Secondary-index query with filter expression\\n\");\n",
    "splitAssignments = assignSplits(ReqSplits, EXACT_NUM_SPLITS);\n",
    "//assignmentSummary(splitAssignments);\n",
    "processSplits(splitAssignments, NumWorkers);\n",
    "//workerSummary();\n",
    "System.out.println();\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Varying max-records chunk size\n",
    "Vary the chunk size from 10 to 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max-records chunk size: 10\n",
      "100 splits: \n",
      "\tSplit: 0, start: 0, count: 41\n",
      "\tSplit: 95, start: 3895, count: 41\n",
      "\tSplit: 96, start: 3936, count: 40\n",
      "\tSplit: 99, start: 4056, count: 40\n",
      "50 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 4 seconds.\n",
      "Records by worker (~50 worker sample): 0:1933 1:2080 2:2025 3:2061 4:2081 5:2088 6:2061 7:1971 8:2040 9:2007 10:2021 11:2006 12:1982 13:2012 14:1945 15:2002 16:2018 17:1951 18:1999 19:2008 20:1981 21:1984 22:1941 23:1985 24:2021 25:1954 26:2005 27:1987 28:2043 29:1999 30:2012 31:2106 32:1930 33:2091 34:1975 35:1950 36:1940 37:2046 38:1917 39:1892 40:1982 41:1927 42:2061 43:2062 44:1968 45:1986 46:2021 47:1943 48:1943 49:2057 \n",
      "\n",
      "Max-records chunk size: 25\n",
      "50 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 2 seconds.\n",
      "\n",
      "Max-records chunk size: 100\n",
      "50 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 0 seconds.\n",
      "\n",
      "Max-records chunk size: 300\n",
      "50 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 0 seconds.\n",
      "\n",
      "Max-records chunk size: 500\n",
      "50 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 0 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "int ReqSplits = 100;\n",
    "int NumWorkers = 50;\n",
    "ProcessingMode = PROCESSING_MODE_ASYNC;\n",
    "QueryType = PRIMARY_INDEX_QUERY;\n",
    "QueryFilter = QUERY_FILTER_NONE;\n",
    "\n",
    "ChunkSize = 10;\n",
    "System.out.format(\"Max-records chunk size: %d\\n\", ChunkSize);\n",
    "splitAssignments = assignSplits(ReqSplits, EXACT_NUM_SPLITS);\n",
    "assignmentSummary(splitAssignments);\n",
    "processSplits(splitAssignments, NumWorkers);\n",
    "workerSummary();\n",
    "System.out.println();\n",
    "\n",
    "ChunkSize = 25;\n",
    "System.out.format(\"Max-records chunk size: %d\\n\", ChunkSize);\n",
    "splitAssignments = assignSplits(ReqSplits, EXACT_NUM_SPLITS);\n",
    "//assignmentSummary(splitAssignments);\n",
    "processSplits(splitAssignments, NumWorkers);\n",
    "//workerSummary();\n",
    "System.out.println();\n",
    "\n",
    "ChunkSize = 100;\n",
    "System.out.format(\"Max-records chunk size: %d\\n\", ChunkSize);\n",
    "splitAssignments = assignSplits(ReqSplits, EXACT_NUM_SPLITS);\n",
    "//assignmentSummary(splitAssignments);\n",
    "processSplits(splitAssignments, NumWorkers);\n",
    "//workerSummary();\n",
    "System.out.println();\n",
    "\n",
    "ChunkSize = 300;\n",
    "System.out.format(\"Max-records chunk size: %d\\n\", ChunkSize);\n",
    "splitAssignments = assignSplits(ReqSplits, EXACT_NUM_SPLITS);\n",
    "//assignmentSummary(splitAssignments);\n",
    "processSplits(splitAssignments, NumWorkers);\n",
    "//workerSummary();\n",
    "System.out.println();\n",
    "\n",
    "ChunkSize = 500;\n",
    "System.out.format(\"Max-records chunk size: %d\\n\", ChunkSize);\n",
    "splitAssignments = assignSplits(ReqSplits, EXACT_NUM_SPLITS);\n",
    "//assignmentSummary(splitAssignments);\n",
    "processSplits(splitAssignments, NumWorkers);\n",
    "//workerSummary();\n",
    "System.out.println();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select and run with your own parameters\n",
    "Experiment with the values in the following cell and see what results you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with parameter values (specify)\n",
      "1000 splits: \n",
      "\tSplit: 0, start: 0, count: 5\n",
      "\tSplit: 95, start: 475, count: 5\n",
      "\tSplit: 96, start: 480, count: 4\n",
      "\tSplit: 999, start: 4092, count: 4\n",
      "100 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 2 seconds.\n",
      "Records by worker (~50 worker sample): 0:751 2:1000 4:902 6:919 8:841 10:888 12:1347 14:954 16:1213 18:782 20:914 22:1008 24:886 26:945 28:926 30:916 32:781 34:794 36:864 38:866 40:887 42:795 44:911 46:972 48:1092 50:1234 52:1151 54:908 56:853 58:769 60:884 62:1319 64:1070 66:984 68:1115 70:1391 72:867 74:793 76:1045 78:1101 80:971 82:1141 84:866 86:1082 88:873 90:1245 92:920 94:1128 96:1074 98:902 \n"
     ]
    }
   ],
   "source": [
    "ProcessingMode = PROCESSING_MODE_SYNC;\n",
    "QueryType = PRIMARY_INDEX_QUERY;\n",
    "QueryFilter = QUERY_FILTER_NONE;\n",
    "ChunkSize = 20;\n",
    "\n",
    "// the following filter expression chooses records with even values of bin1 - CAN CHANGE TO A DIFFERENT EXPRESSION\n",
    "//    used when QueryFilter = QUERY_FILTER_INCLUDE\n",
    "IncludeQueryFilterExp = Exp.eq(Exp.mod(Exp.intBin(\"bin1\"), Exp.val(2)), Exp.val(0));\n",
    "\n",
    "// the following query predicate is a range filter for records with 50001 <= bin1 <= 100000 - CAN CHANGE TO A DIFFERENT QUERY PREDICATE\n",
    "//    used when QueryType = SECONDARY_INDEX_QUERY\n",
    "SecondaryIndexQueryPredicate = Filter.range(\"bin1\", 50001, 100000);\n",
    "\n",
    "int ReqSplits = 1000;\n",
    "int SplitType = EXACT_NUM_SPLITS;\n",
    "int NumWorkers = 100;\n",
    "\n",
    "System.out.format(\"Running with parameter values (specify)\\n\");\n",
    "SplitAssignment[] splitAssignments = assignSplits(ReqSplits, EXACT_NUM_SPLITS);\n",
    "assignmentSummary(splitAssignments);\n",
    "processSplits(splitAssignments, NumWorkers);\n",
    "workerSummary();\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Takeaways and Conclusion\n",
    "The ability to retrieve a large data set in parallel streams for processing in a large number of workers is essential to high throughput applications. Aerospike provides mechanisms to divide a large data set over an arbitrary number of splits and process each split in smaller chunks at a time. The notebook implements an algorithm for split assignments, and provides a framework for parallel processing a query over splits. It also demonstrates parallel processing using varying values of splits, workers, query and filter, chunk size, and processing mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Exploration and Resources\n",
    "Here are some links for further exploration\n",
    "\n",
    "Resources\n",
    "- [Processing Large Data Sets with Fine Grained Streams](https://deveveloper.aerospike.com/blog/fine-grained-streams) (blog post)\n",
    "- [Aerospike Developer Hub](https://deveveloper.aerospike.com)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "codemirror_mode": "java",
   "file_extension": ".jshell",
   "mimetype": "text/x-java-source",
   "name": "Java",
   "pygments_lexer": "java",
   "version": "11.0.8+10-LTS"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
